#!/usr/bin/env python3
# Copyright 2024 K. D. Murray
# This Source Code Form is subject to the terms of the Mozilla Public
# License, v. 2.0. If a copy of the MPL was not distributed with this
# file, You can obtain one at http://mozilla.org/MPL/2.0/.

import argparse
import re
from collections import defaultdict
from pathlib import Path
from snakemake.api import SnakemakeApi
import json
from sys import stderr

SNAKEFILE=r"""
configfile: "config.json"


def all_inputs(wc):
    res = ["output/multiqc.html",]
    for sample in config["samples"]:
        res.append(dirs["temp"]/ f"aln/{sample}.bam")
        if config.get("kraken_db"):
            res.append(dirs["output"]/f"taxonid/kraken_{sample}_report.txt")

    return res
rule all:
    input: all_inputs


rule subsample:
    input:
        r1=lambda wc: config["samples"][wc.sample]["R1"],
        r2=lambda wc: config["samples"][wc.sample]["R2"],
    output:
        r1=temp("tmp/reads/sub/{sample}_subsample_R1.fastq"),
        r2=temp("tmp/reads/sub/{sample}_subsample_R2.fastq"),
    log:
        "tmp/reads/sub/{sample}_subsample.log",
    threads: 1
    container: "docker://quay.io/mbhall88/rasusa"
    params:
        seed=config["subsample_seed"],
        nreads=config["subsample"],
    shell:
        "( rasusa reads"
        "   --num {params.nreads}"
        "   --seed {params.seed}"
        "   -o {output.r1} -o {output.r2}"
        "   {input.r1} {input.r2}"
        ") 2>{log}"


def fastp_input(wc):
    if config["subsample"] > 0:
        return {
            "r1": dirs["temp"]/f"reads/sub/{wc.sample}_subsample_R1.fastq",
            "r2": dirs["temp"]/f"reads/sub/{wc.sample}_subsample_R2.fastq",
        }
    else:
        return {
            "r1": config["samples"][wc.sample]["R1"],
            "r2": config["samples"][wc.sample]["R2"],
        }
rule fastp:
    input:
        unpack(fastp_input)
    output:
        r1=temp("tmp/reads/qc/{sample}_qc_R1.fastq"),
        r2=temp("tmp/reads/qc/{sample}_qc_R2.fastq"),
        rs=temp("tmp/reads/qc/{sample}_qc_SE.fastq"),
        json="tmp/reads/qc/{sample}_qc.json",
        html="tmp/reads/qc/{sample}_qc.html",
    log:
        "tmp/reads/qc/{sample}_qc.log",
    threads: 8
    container: "docker://quay.io/biocontainers/fastp:0.23.4--hadf994f_3"
    shell:
        "fastp "
        "   --in1 {input.r1}"
        "   --in2 {input.r2}"
        "   --out1 {output.r1}"
        "   --out2 {output.r2}"
        "   --unpaired1 {output.rs}"
        "   --unpaired2 {output.rs}"
        "   --thread {threads}"
        "   --json {output.json}"
        "   --html {output.html}"
        "   --low_complexity_filter"
        "   --detect_adapter_for_pe"
        "   --cut_tail"
        "   --trim_poly_x"
        ">{log} 2>&1"

rule kraken:
    input:
        r1="tmp/reads/qc/{sample}_qc_R1.fastq",
        r2="tmp/reads/qc/{sample}_qc_R2.fastq",
    output:
        report="output/taxonid/kraken_{sample}_report.txt",
    log:
        "output/taxonid/kraken_{sample}.log",
    resources:
        runtime=90,
        mem="100G",
    threads: 16
    container: "docker://ghcr.io/kdm9/kraken2:latest"
    params:
        db=config.get("kraken_db"),
    shell:
        "kraken2"
        "   --db {params.db}"
        "   --memory-mapping"
        "   --threads {threads}"
        "   --use-names"
        "   --report-minimizer-data"
        "   --report {output.report}"
        "   --paired"
        "   {input.r1} {input.r2}"
        "   >/dev/null 2>{log}"

rule idxref:
    input:
        ref=lambda wc: config["reference"],
    output:
        idx=temp("tmp/ref.mmi"),
    log:
        "tmp/ref.mmi.log",
    threads: 4
    container: "docker://ghcr.io/kdm9/minimap2-samtools:latest"
    shell:
        "minimap2 -x sr -d {output.idx} -t {threads} {input.ref} &>{log}"

rule map:
    input:
        r1="tmp/reads/qc/{sample}_qc_R1.fastq",
        r2="tmp/reads/qc/{sample}_qc_R2.fastq",
        idx="tmp/ref.mmi",
    output:
        bam="tmp/aln/{sample}.bam",
        bai="tmp/aln/{sample}.bam.bai",
        minimap="output/aln/{sample}_minimap.log",
        markdup="output/aln/{sample}_markdup.log",
    log:
        log="tmp/aln/{sample}.log",
    container: "docker://ghcr.io/kdm9/minimap2-samtools:latest"
    threads: 16
    resources:
        mem="16G"
    params:
        mem=lambda wc, input, output, resources: int((resources.mem_mb*0.4)/resources._cores),
    shell:
        "( minimap2 -ax sr"
        "   -t {threads}"
        "   {input.idx}"
        "   {input.r1} {input.r2}"
        "   2>{output.minimap}"
        " | samtools fixmate "
        "   -m"
        "   -@ {threads}"
        "   -u"
        "   /dev/stdin"
        "   /dev/stdout"
        " | samtools sort"
        "   -T ${{TMPDIR:-/tmp}}/{wildcards.sample}_sort_$RANDOM"
        "   --output-fmt bam,level=0"
        "   -@ {threads}"
        "   -m {params.mem}m" # multiplied by {threads}
        "   /dev/stdin"
        " | samtools markdup"
        "   -T ${{TMPDIR:-/tmp}}/{wildcards.sample}_markdup_$RANDOM"
        "   -s" # report stats
        "   -@ {threads}"
        "   --output-fmt bam,level=0"
        "   /dev/stdin"
        "   /dev/stdout"
        " 2>{output.markdup}"
        " | tee {output.bam}"
        " | samtools index - {output.bai}"
        " ) > {log.log} 2>&1"

def multiqc_input(wc):
    res = []
    for sample in config["samples"]:
        res.append(dirs["temp"]/ f"aln/{sample}_minimap.log")
        res.append(dirs["temp"]/ f"aln/{sample}_markdup.log")
        res.append(dirs["temp"]/ f"reads/qc/{sample}_qc.json")
        if config.get("kraken_db"):
            res.append(dirs["output"]/f"taxonid/kraken_{sample}_report.txt")
    return res

rule multiqc_kraken:
    input: multiqc_input
    output:
        html="output/multiqc.html",
    log:
        "output/multiqc.log",
    container: "docker://multiqc/multiqc:v1.20"
    shell:
        "multiqc"
        "   --no-megaqc-upload"
        "   --interactive"
        "   --no-data-dir"
        "   --filename {output.html}"
        "   {input}"
        " >{log} 2>&1"
"""
######################################### END SNAKEFILE #######################################################


def existing_path(arg):
    """Parse a CLI argument that must exist to a pathlib.Path (can be dir or file, so long as it exists)"""
    p = Path(arg)
    if not p.exists():
        raise ValueError(f"{arg} does not exist")
    return p


class PathJsonEncoder(json.JSONEncoder):
    """A JSONEncoder that knows about Paths"""
    def default(self, o):
        import pathlib
        if isinstance(o, pathlib.PurePath):
            return str(o)
        return super().default(o)


def fastq_pairer(fastqs):
    samples = defaultdict(dict)
    for fastq in fastqs:
        fn = Path(fastq).name
        fn = re.sub(r"(\.fq|\.fastq)(\.(gz|bz2|zstd|zst))?", "", fn)
        m = re.search(r"(.+)_(R[12])(?=(_001|$))", fn)
        key = fn
        if not m:
            read = "??"
            print(f"WARNING: fastq with unknown pairing. This program assumes raw, paired end illumina data! ({fastq})", file=stderr)
        else:
            key = m.group(1)
            read = m.group(2)
        samples[key][read] = fastq
    return dict(samples.items())


def main(argv=None):
    ap = argparse.ArgumentParser()
    ap.add_argument("--reference", "-r", type=existing_path, required=True,
        help="Reference Genome")
    ap.add_argument("--seed", "-S", type=int, default=3112342,
        help="Random Seed for subsampling")
    ap.add_argument("--subsample", "-s", type=int, default=0,
        help="Number of reads to subsample (0 to disable, which is the default)")
    ap.add_argument("--kraken-db", "-k", type=existing_path,
        help="Run Kraken + Bracken, using this DB (give dir name)")
    ap.add_argument("--workdir", type=Path, default=Path("seqchk.out"),
        help="Working dir")
    ap.add_argument("fastqs", type=existing_path, nargs="+")

    args = ap.parse_args(argv)
    args.workdir.mkdir(exist_ok=True)
    with open(args.workdir / "config.json", "w") as fh:
        json.dump({
            "samples": fastq_pairer(args.fastqs),
            "reference": args.reference.resolve(),
            "subsample": args.subsample,
            "subsample_seed": args.seed,
            "kraken_db": args.kraken_db,
        }, fh, indent=4, cls=PathJsonEncoder)

    with open(args.workdir / "Snakefile", "w") as fh:
        fh.write(SNAKEFILE)

    with open(args.workdir / ".gitignore", "w") as fh:
        print("tmp", file=fh)
        print("output", file=fh)
        print(".snakemake", file=fh)

    print("Workflow written to {args.workdir}. To execute, please run `snakemake` from there, with your profile or any of the usual arguments needed to run snakemake locally.")

if __name__ == "__main__":
    main()
